{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import modules and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data/diabetic_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_diag\n",
       "0    63742\n",
       "1    38024\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine whether the diabetes diagnosis was in the top 3\n",
    "# Drop the diagnoses, they are too scattered\n",
    "import re\n",
    "DIABETES_REGEX = re.compile(\"250\")\n",
    "isDiabetes = lambda s: DIABETES_REGEX.match(s)\n",
    "df[\"primary_diag\"] = (df[\"diag_1\"].str.contains(\"^250\") |\n",
    "                      df[\"diag_2\"].str.contains(\"^250\") |\n",
    "                      df[\"diag_3\"].str.contains(\"^250\")).astype(\"int\")\n",
    "df.drop([\"diag_1\", \"diag_2\", \"diag_3\"], axis=1, inplace=True)\n",
    "df.groupby(\"primary_diag\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "      <th>primary_diag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              race  gender      age  admission_type_id  \\\n",
       "0        Caucasian  Female   [0-10)                  6   \n",
       "1        Caucasian  Female  [10-20)                  1   \n",
       "2  AfricanAmerican  Female  [20-30)                  1   \n",
       "3        Caucasian    Male  [30-40)                  1   \n",
       "4        Caucasian    Male  [40-50)                  1   \n",
       "\n",
       "   discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "0                        25                    1                 1   \n",
       "1                         1                    7                 3   \n",
       "2                         1                    7                 2   \n",
       "3                         1                    7                 2   \n",
       "4                         1                    7                 1   \n",
       "\n",
       "   num_lab_procedures  num_procedures  num_medications  ...  insulin  \\\n",
       "0                  41               0                1  ...       No   \n",
       "1                  59               0               18  ...       Up   \n",
       "2                  11               5               13  ...       No   \n",
       "3                  44               1               16  ...       Up   \n",
       "4                  51               0                8  ...   Steady   \n",
       "\n",
       "   glyburide-metformin  glipizide-metformin  glimepiride-pioglitazone  \\\n",
       "0                   No                   No                        No   \n",
       "1                   No                   No                        No   \n",
       "2                   No                   No                        No   \n",
       "3                   No                   No                        No   \n",
       "4                   No                   No                        No   \n",
       "\n",
       "  metformin-rosiglitazone metformin-pioglitazone change diabetesMed  \\\n",
       "0                      No                     No     No          No   \n",
       "1                      No                     No     Ch         Yes   \n",
       "2                      No                     No     No         Yes   \n",
       "3                      No                     No     Ch         Yes   \n",
       "4                      No                     No     Ch         Yes   \n",
       "\n",
       "  readmitted primary_diag  \n",
       "0         NO            1  \n",
       "1        >30            1  \n",
       "2         NO            1  \n",
       "3         NO            1  \n",
       "4         NO            1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove columns...\n",
    "#  * encounter_id, patient_nbr (identification)\n",
    "#  * weight, payer_code, medical_specialty (too sparse)\n",
    "#  * diag_1, diag_2, diag_3 (too specific)\n",
    "df.drop([\"encounter_id\", \"patient_nbr\", \"weight\", \"payer_code\", \"medical_specialty\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99340, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter by...\n",
    "#  * Must have a gender\n",
    "df = df[df[\"gender\"] != \"Unknown/Invalid\"]\n",
    "\n",
    "#  * Must not be discharged by death or hospice\n",
    "df = df.loc[~df[\"discharge_disposition_id\"].isin([11, 13, 14, 19, 20, 21])]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>discharged_home</th>\n",
       "      <th>admission_source</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "      <th>primary_diag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.15</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.442748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>...</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076336</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.35</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.328244</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>...</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              race  gender   age admission_type  discharged_home  \\\n",
       "0        Caucasian  Female  0.05          Other                0   \n",
       "1        Caucasian  Female  0.15      Emergency                1   \n",
       "2  AfricanAmerican  Female  0.25      Emergency                1   \n",
       "3        Caucasian    Male  0.35      Emergency                1   \n",
       "4        Caucasian    Male  0.45      Emergency                1   \n",
       "\n",
       "  admission_source  time_in_hospital  num_lab_procedures  num_procedures  \\\n",
       "0            Other          0.000000            0.305344        0.000000   \n",
       "1            Other          0.153846            0.442748        0.000000   \n",
       "2            Other          0.076923            0.076336        0.833333   \n",
       "3            Other          0.076923            0.328244        0.166667   \n",
       "4            Other          0.000000            0.381679        0.000000   \n",
       "\n",
       "   num_medications  ...  insulin  glyburide-metformin  glipizide-metformin  \\\n",
       "0           0.0000  ...       No                   No                   No   \n",
       "1           0.2125  ...       Up                   No                   No   \n",
       "2           0.1500  ...       No                   No                   No   \n",
       "3           0.1875  ...       Up                   No                   No   \n",
       "4           0.0875  ...   Steady                   No                   No   \n",
       "\n",
       "   glimepiride-pioglitazone metformin-rosiglitazone metformin-pioglitazone  \\\n",
       "0                        No                      No                     No   \n",
       "1                        No                      No                     No   \n",
       "2                        No                      No                     No   \n",
       "3                        No                      No                     No   \n",
       "4                        No                      No                     No   \n",
       "\n",
       "  change diabetesMed readmitted primary_diag  \n",
       "0     No          No         NO            1  \n",
       "1     Ch         Yes        >30            1  \n",
       "2     No         Yes         NO            1  \n",
       "3     Ch         Yes         NO            1  \n",
       "4     Ch         Yes         NO            1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize continuous columns to [0, 1]\n",
    "cols_continuous = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications',\n",
    "       'number_outpatient', 'number_emergency', 'number_inpatient','number_diagnoses']\n",
    "\n",
    "for col in cols_continuous:\n",
    "    lo, hi = df[col].min(), df[col].max()\n",
    "    df[col] = (df[col] - lo) / (hi - lo)\n",
    "\n",
    "# Normalize numerically-categorical columns (i.e. age)\n",
    "AGE_MAPPING = {\"[{}-{})\".format(i * 10, (i + 1) * 10): i * 0.1 + 0.05 for i in range(10)}\n",
    "df[\"age\"] = df[\"age\"].apply(lambda s: AGE_MAPPING[s])\n",
    "df[[\"age\"] + cols_continuous].head()\n",
    "\n",
    "# Manipulate categorical columns\n",
    "cols_categorical = ['race', 'gender',\n",
    "        'admission_type', 'admission_source',\n",
    "        'max_glu_serum', 'A1Cresult',\n",
    "        'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "        'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "        'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "        'tolazamide', 'insulin',\n",
    "        'glyburide-metformin', 'glipizide-metformin',\n",
    "        'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
    "        'metformin-pioglitazone', 'change', 'diabetesMed',\n",
    "        'examide', 'citoglipton']\n",
    "\n",
    "# Create an \"Unknown\" category for race\n",
    "df[\"race\"] = df[\"race\"].replace(\"?\", \"Unknown\")\n",
    "\n",
    "# Consolidate admissions types\n",
    "ADMISSION_TYPE_MAPPING = {\n",
    "    1: \"Emergency\",\n",
    "    2: \"Urgent\",\n",
    "    3: \"Elective\"\n",
    "}\n",
    "df[\"admission_type_id\"] = df[\"admission_type_id\"].apply(lambda s: ADMISSION_TYPE_MAPPING.get(s, \"Other\"))\n",
    "\n",
    "# Discharge disposition is either going home OK or not going home OK\n",
    "df[\"discharge_disposition_id\"] = (df[\"discharge_disposition_id\"] == 1).astype(\"int\")\n",
    "\n",
    "# Admission source is either Emergency, Referral, or Other\n",
    "ADMISSION_SOURCE_MAPPING = {\n",
    "    1: \"EmergencyRoom\",\n",
    "    7: \"Referral\"\n",
    "}\n",
    "df[\"admission_source_id\"] = df[\"admission_type_id\"].apply(lambda s: ADMISSION_SOURCE_MAPPING.get(s, \"Other\"))\n",
    "\n",
    "df.rename(columns={\n",
    "    \"admission_type_id\": \"admission_type\",\n",
    "    \"discharge_disposition_id\": \"discharged_home\",\n",
    "    \"admission_source_id\": \"admission_source\"}, inplace=True)\n",
    "#df[\"race\", \"admission_type\", \"admission_source\", \"discharged_home\"].head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insignificant: ['admission_source', 'nateglinide', 'chlorpropamide', 'acetohexamide', 'tolbutamide', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'examide', 'citoglipton']\n",
      "Significant: ['race', 'gender', 'admission_type', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'insulin', 'change', 'diabetesMed']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>discharged_home</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>...</th>\n",
       "      <th>rosiglitazone_Steady</th>\n",
       "      <th>rosiglitazone_Up</th>\n",
       "      <th>insulin_Down</th>\n",
       "      <th>insulin_No</th>\n",
       "      <th>insulin_Steady</th>\n",
       "      <th>insulin_Up</th>\n",
       "      <th>change_Ch</th>\n",
       "      <th>change_No</th>\n",
       "      <th>diabetesMed_No</th>\n",
       "      <th>diabetesMed_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.442748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076336</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.328244</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  discharged_home  time_in_hospital  num_lab_procedures  \\\n",
       "0  0.05                0          0.000000            0.305344   \n",
       "1  0.15                1          0.153846            0.442748   \n",
       "2  0.25                1          0.076923            0.076336   \n",
       "3  0.35                1          0.076923            0.328244   \n",
       "4  0.45                1          0.000000            0.381679   \n",
       "\n",
       "   num_procedures  num_medications  number_outpatient  number_emergency  \\\n",
       "0        0.000000           0.0000           0.000000               0.0   \n",
       "1        0.000000           0.2125           0.000000               0.0   \n",
       "2        0.833333           0.1500           0.047619               0.0   \n",
       "3        0.166667           0.1875           0.000000               0.0   \n",
       "4        0.000000           0.0875           0.000000               0.0   \n",
       "\n",
       "   number_inpatient  number_diagnoses  ...  rosiglitazone_Steady  \\\n",
       "0          0.000000          0.000000  ...                     0   \n",
       "1          0.000000          0.533333  ...                     0   \n",
       "2          0.047619          0.333333  ...                     0   \n",
       "3          0.000000          0.400000  ...                     0   \n",
       "4          0.000000          0.266667  ...                     0   \n",
       "\n",
       "   rosiglitazone_Up  insulin_Down  insulin_No  insulin_Steady  insulin_Up  \\\n",
       "0                 0             0           1               0           0   \n",
       "1                 0             0           0               0           1   \n",
       "2                 0             0           1               0           0   \n",
       "3                 0             0           0               0           1   \n",
       "4                 0             0           0               1           0   \n",
       "\n",
       "   change_Ch  change_No  diabetesMed_No  diabetesMed_Yes  \n",
       "0          0          1               1                0  \n",
       "1          1          0               0                1  \n",
       "2          0          1               0                1  \n",
       "3          1          0               0                1  \n",
       "4          1          0               0                1  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle categorical columns...\n",
    "#  1. Remove categorical columns that are almost uniform (>99% of entries are one thing)\n",
    "#  2. Split other columns into multiple boolean columns\n",
    "n_rows = df.shape[0]\n",
    "cols_insignificant = []\n",
    "cols_significant = []\n",
    "for col in cols_categorical:\n",
    "    freqs = dict(df.groupby(col).size())\n",
    "    \n",
    "    # Remove this column\n",
    "    if any([float(value)/float(n_rows) > 0.99 for value in freqs.values()]):\n",
    "        cols_insignificant.append(col)\n",
    "    \n",
    "    else:\n",
    "        # Sanity check\n",
    "        assert(len(freqs) > 1)\n",
    "        cols_significant.append(col)\n",
    "        \n",
    "        # Convert to column to string if not already string type\n",
    "        if df[col].dtype != str:\n",
    "            df[col] = df[col].astype(str)\n",
    "            \n",
    "# Extract output\n",
    "df_output = pd.get_dummies(df[\"readmitted\"])\n",
    "df.drop([\"readmitted\"], axis=1, inplace=True)\n",
    "\n",
    "df_cat = pd.get_dummies(df[cols_significant], drop_first=False)\n",
    "df_input = pd.concat([df, df_cat], axis=1)\n",
    "\n",
    "df_input.drop(cols_insignificant + cols_significant, axis=1, inplace=True)\n",
    "\n",
    "print(\"Insignificant: {}\".format(cols_insignificant))\n",
    "print(\"Significant: {}\".format(cols_significant))\n",
    "df_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>discharged_home</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>...</th>\n",
       "      <th>insulin_No</th>\n",
       "      <th>insulin_Steady</th>\n",
       "      <th>insulin_Up</th>\n",
       "      <th>change_Ch</th>\n",
       "      <th>change_No</th>\n",
       "      <th>diabetesMed_No</th>\n",
       "      <th>diabetesMed_Yes</th>\n",
       "      <th>OUTPUT_&lt;30</th>\n",
       "      <th>OUTPUT_&gt;30</th>\n",
       "      <th>OUTPUT_NO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.442748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076336</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.328244</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  discharged_home  time_in_hospital  num_lab_procedures  \\\n",
       "0  0.05                0          0.000000            0.305344   \n",
       "1  0.15                1          0.153846            0.442748   \n",
       "2  0.25                1          0.076923            0.076336   \n",
       "3  0.35                1          0.076923            0.328244   \n",
       "4  0.45                1          0.000000            0.381679   \n",
       "\n",
       "   num_procedures  num_medications  number_outpatient  number_emergency  \\\n",
       "0        0.000000           0.0000           0.000000               0.0   \n",
       "1        0.000000           0.2125           0.000000               0.0   \n",
       "2        0.833333           0.1500           0.047619               0.0   \n",
       "3        0.166667           0.1875           0.000000               0.0   \n",
       "4        0.000000           0.0875           0.000000               0.0   \n",
       "\n",
       "   number_inpatient  number_diagnoses  ...  insulin_No  insulin_Steady  \\\n",
       "0          0.000000          0.000000  ...           1               0   \n",
       "1          0.000000          0.533333  ...           0               0   \n",
       "2          0.047619          0.333333  ...           1               0   \n",
       "3          0.000000          0.400000  ...           0               0   \n",
       "4          0.000000          0.266667  ...           0               1   \n",
       "\n",
       "   insulin_Up  change_Ch  change_No  diabetesMed_No  diabetesMed_Yes  \\\n",
       "0           0          0          1               1                0   \n",
       "1           1          1          0               0                1   \n",
       "2           0          0          1               0                1   \n",
       "3           1          1          0               0                1   \n",
       "4           0          1          0               0                1   \n",
       "\n",
       "   OUTPUT_<30  OUTPUT_>30  OUTPUT_NO  \n",
       "0           0           0          1  \n",
       "1           0           1          0  \n",
       "2           0           0          1  \n",
       "3           0           0          1  \n",
       "4           0           0          1  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_input, df_output], axis=1)\n",
    "df.rename(columns={\"<30\": \"OUTPUT_<30\", \">30\": \"OUTPUT_>30\", \"NO\": \"OUTPUT_NO\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "N_INPUTS = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69538, 14901, 14901)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull out validation (15%) and test (15%) data from training (70%) data\n",
    "df_valid_test = df.sample(frac=0.3, random_state=0xda)\n",
    "df_training = df.drop(df_valid_test.index)\n",
    "\n",
    "df_valid = df_valid_test.sample(frac=0.5, random_state=0xdb)\n",
    "df_test = df_valid_test.drop(df_valid.index, axis=0)\n",
    "\n",
    "df_training.shape[0], df_valid.shape[0], df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingBatches:\n",
    "\n",
    "    def __init__(self, nn, batch_size=16):\n",
    "        self.nn = nn\n",
    "        self.batch_size = batch_size\n",
    "        self.bounds = max([d.shape[0] for d in nn.training_data])\n",
    "        self.it = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.it >= self.bounds:\n",
    "            raise StopIteration\n",
    "\n",
    "        output = np.concatenate([self.getSlice(d, self.it, self.batch_size) for d in self.nn.training_data])\n",
    "        self.it += self.batch_size\n",
    "        return output[:, :N_INPUTS], output[:, N_INPUTS:]\n",
    "\n",
    "    # Code must work with Python 2 and 3\n",
    "    next = __next__\n",
    "\n",
    "    def getSlice(self, array, start, length):\n",
    "        start = start % array.shape[0]\n",
    "        if start + length >= array.shape[0]:\n",
    "            return np.concatenate((array[start:], array[:(start + length) % array.shape[0]]), axis=0)\n",
    "        else:\n",
    "            return array[start:start + length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalPreprocessor:\n",
    "    \n",
    "    def __init__(self, df, output_categories):\n",
    "        self.output_categories = output_categories\n",
    "        self.df = df\n",
    "        self.is_modified = False\n",
    "        \n",
    "    def modifyDatafile(self):\n",
    "        \n",
    "        if self.is_modified:\n",
    "            return self.df\n",
    "        \n",
    "        self.df = self.df.copy()\n",
    "        self.is_modified = True\n",
    "        \n",
    "        if self.output_categories == \"any\":\n",
    "            self.df[\"OUTPUT_ANY\"] = self.df[\"OUTPUT_<30\"] + self.df[\"OUTPUT_>30\"]\n",
    "            self.df.drop([\"OUTPUT_<30\", \"OUTPUT_>30\"], axis=1, inplace=True)\n",
    "\n",
    "        elif self.output_categories == \"rapid\":\n",
    "            self.df[\"OUTPUT_NO\"] = self.df[\"OUTPUT_>30\"] + self.df[\"OUTPUT_NO\"]\n",
    "            self.df.drop([\"OUTPUT_>30\"], axis=1, inplace=True)\n",
    "            \n",
    "        return self.df\n",
    "    \n",
    "    def getArraysByOutput(self):\n",
    "        \n",
    "        if not self.is_modified:\n",
    "            self.modifyDatafile()\n",
    "            \n",
    "        if self.output_categories == \"three\":\n",
    "            return (\n",
    "                self.df[self.df[\"OUTPUT_<30\"] == 1].to_numpy(),\n",
    "                self.df[self.df[\"OUTPUT_>30\"] == 1].to_numpy(),\n",
    "                self.df[self.df[\"OUTPUT_NO\"] == 1].to_numpy()\n",
    "            )\n",
    "\n",
    "        elif self.output_categories == \"any\":\n",
    "            return (\n",
    "                self.df[self.df[\"OUTPUT_ANY\"] == 1].to_numpy(),\n",
    "                self.df[self.df[\"OUTPUT_NO\"] == 1].to_numpy()\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            return (\n",
    "                self.df[self.df[\"OUTPUT_<30\"] == 1].to_numpy(),\n",
    "                self.df[self.df[\"OUTPUT_NO\"] == 1].to_numpy()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseDense(tf.keras.layers.Dense):\n",
    "    \n",
    "    def __init__(self,\n",
    "            units, activation=None, use_bias=True,\n",
    "            kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "            kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "            kernel_constraint=None, bias_constraint=None, **kwargs):\n",
    "        \n",
    "        super(SparseDense, self).__init__(\n",
    "            units, activation, use_bias, kernel_initializer, bias_initializer,\n",
    "            kernel_regularizer, bias_regularizer, activity_regularizer,\n",
    "            kernel_constraint, bias_constraint, **kwargs)\n",
    "            \n",
    "        self.sparsity_matrix_initializer = tf.keras.initializers.Ones\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(SparseDense, self).build(input_shape)\n",
    "        self.sparsity_matrix_tensor = self.add_weight(\n",
    "            name=\"sparsity_matrix\",\n",
    "            shape=self.kernel.shape,\n",
    "            initializer=self.sparsity_matrix_initializer,\n",
    "            regularizer=None,\n",
    "            constraint=None,\n",
    "            dtype=self.dtype,\n",
    "            trainable=False)\n",
    "        self.sparsity_matrix = np.ones(self.kernel.shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        # Mask kernel with sparsity matrix\n",
    "        #masked_kernel = tf.keras.backend.multiply(self.kernel, self.sparsity_matrix)\n",
    "        masked_kernel = self.kernel * self.sparsity_matrix\n",
    "        output = tf.keras.backend.dot(inputs, masked_kernel)\n",
    "        return tf.keras.backend.bias_add(output, self.bias, data_format=\"channels_last\")\n",
    "    \n",
    "    def makeSparse(self, p):\n",
    "        \n",
    "        kernel = tf.keras.backend.get_value(self.kernel)\n",
    "        \n",
    "        # Remove some percentage of the remaining weights\n",
    "        items = []\n",
    "        for row in range(kernel.shape[0]):\n",
    "            for col in range(kernel.shape[1]):\n",
    "                if self.sparsity_matrix[row][col] > 0:\n",
    "                    items.append((row, col, kernel[row][col]))\n",
    "                    \n",
    "        items.sort(key=lambda x: abs(x[2]))\n",
    "        num_to_remove = int(np.ceil(len(items) * p))\n",
    "        for row, col, val in items[:num_to_remove]:\n",
    "            self.sparsity_matrix[row][col] = 0\n",
    "            \n",
    "        tf.keras.backend.set_value(self.sparsity_matrix_tensor, self.sparsity_matrix)\n",
    "        \n",
    "        return 1 - float(len(items) - num_to_remove) / int(self.kernel.shape[0] * self.kernel.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, df, df_validation, df_testing, layer_sizes, output_categories, dropout, batch_size):\n",
    "        self.dropout = dropout\n",
    "        self.output_categories = output_categories\n",
    "        self.batch_size = batch_size\n",
    "        self.layer_sizes = layer_sizes\n",
    "        \n",
    "        # Parameter to horizontally compress the sigmoid activation\n",
    "        self.activation_param = 1.0\n",
    "        \n",
    "        self.sparsity = 0.0\n",
    "        \n",
    "        # Prepare training data\n",
    "        training_processor = CategoricalPreprocessor(df, output_categories)\n",
    "        self.training_data = training_processor.getArraysByOutput()\n",
    "        \n",
    "        # Prepare training batches\n",
    "        training_in_out = list(iter(TrainingBatches(self, 32)))\n",
    "        self.training_in = np.concatenate([i for i, o in training_in_out])\n",
    "        self.training_out = np.concatenate([o for i, o in training_in_out])\n",
    "        \n",
    "        # Prepare validation data\n",
    "        validation_processor = CategoricalPreprocessor(df_validation, output_categories)\n",
    "        self.validation_data = validation_processor.modifyDatafile().to_numpy()\n",
    "        self.validation_in = self.validation_data[:, :N_INPUTS]\n",
    "        self.validation_out = self.validation_data[:, N_INPUTS:]\n",
    "        \n",
    "        with open(\"data/validation-{}.pickle\".format(output_categories), \"wb\") as output_file:\n",
    "            pickle.dump({\"in\": self.validation_in, \"out\": self.validation_out}, output_file)\n",
    "        \n",
    "        # Prepare testing data\n",
    "        testing_processor = CategoricalPreprocessor(df_testing, output_categories)\n",
    "        self.testing_data = testing_processor.modifyDatafile().to_numpy()\n",
    "        self.testing_in = self.testing_data[:, :N_INPUTS]\n",
    "        self.testing_out = self.testing_data[:, N_INPUTS:]\n",
    "        \n",
    "        with open(\"data/testing-{}.pickle\".format(output_categories), \"wb\") as output_file:\n",
    "            pickle.dump({\"in\": self.testing_in, \"out\": self.testing_out}, output_file)\n",
    "        \n",
    "        self.classifier = self.makeClassifier()\n",
    "        \n",
    "        \n",
    "    def parametrizedSigmoid(self):\n",
    "        \n",
    "        def sigmoid(x):\n",
    "            # In the original Tensorflow code, x is a Tensor\n",
    "            # For efficiency, x will be scalar-multiplied by the sigmoid\n",
    "            # parameter and then passed to tf.math.sigmoid\n",
    "            scaled = tf.math.scalar_mul(self.activation_param, x)\n",
    "            return tf.math.sigmoid(scaled)\n",
    "        \n",
    "        return sigmoid\n",
    "    \n",
    "    \n",
    "    def makeClassifier(self):\n",
    "        \n",
    "        self.sparse_layers = []\n",
    "        \n",
    "        # Create layers\n",
    "        classifier = tf.keras.Sequential()\n",
    "        \n",
    "        sparse_layer = SparseDense(self.layer_sizes[0], kernel_initializer=\"random_normal\", input_dim=N_INPUTS)\n",
    "        self.sparse_layers.append(sparse_layer)\n",
    "        classifier.add(sparse_layer)\n",
    "        classifier.add(tf.keras.layers.Activation(self.parametrizedSigmoid()))\n",
    "        classifier.add(tf.keras.layers.Dropout(self.dropout))\n",
    "        \n",
    "        for size in self.layer_sizes[1:]:\n",
    "            sparse_layer = tf.keras.layers.Dense(size, kernel_initializer=\"random_normal\")\n",
    "            #self.sparse_layers.append(sparse_layer)\n",
    "            classifier.add(sparse_layer)\n",
    "            classifier.add(tf.keras.layers.Activation(self.parametrizedSigmoid()))\n",
    "            classifier.add(tf.keras.layers.Dropout(self.dropout))\n",
    "            \n",
    "        sparse_layer = tf.keras.layers.Dense(len(self.training_data), kernel_initializer=\"random_normal\")\n",
    "        #self.sparse_layers.append(sparse_layer)\n",
    "        classifier.add(sparse_layer)\n",
    "        classifier.add(tf.keras.layers.Softmax())\n",
    "            \n",
    "        #classifier.add(tf.keras.layers.Dense(\n",
    "        #    len(self.training_data), activation=\"softmax\", kernel_initializer=\"random_normal\"))\n",
    "        \n",
    "        # Compile model\n",
    "        classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",\n",
    "                                metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")])\n",
    "        \n",
    "        return classifier\n",
    "        \n",
    "        \n",
    "    def train(self, epochs=20):\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_accuracy\", mode=\"max\", patience=5, restore_best_weights=False)\n",
    "        \n",
    "        class Logger(tf.keras.callbacks.Callback):\n",
    "            \n",
    "            def __init__(self, sparsity, steepness):\n",
    "                self.sparsity = sparsity\n",
    "                self.steepness = steepness\n",
    "                self.epoch_number = 1\n",
    "            \n",
    "            def on_epoch_end(self, epoch, logs={}):\n",
    "                stats = \", \".join([\"{} = {:.3f}\".format(k, v) for k, v in logs.items()])\n",
    "                print(\"Epoch {} (Sparsity = {}, Steepness = {}): {}\".format(\n",
    "                        self.epoch_number, self.sparsity, self.steepness, stats))\n",
    "                self.epoch_number += 1\n",
    "                \n",
    "        logger = Logger(self.sparsity, self.activation_param)\n",
    "        \n",
    "        return self.classifier.fit(self.training_in, self.training_out,\n",
    "                                   validation_data=(self.validation_in, self.validation_out),\n",
    "                                   batch_size=self.batch_size,\n",
    "                                   epochs=epochs,\n",
    "                                   callbacks=[early_stopping, logger], verbose=0)\n",
    "    \n",
    "    \n",
    "    def evaluate(self):\n",
    "        \n",
    "        def confusionMatrix(predicted, actual):\n",
    "            \n",
    "            matrix = np.zeros((actual.shape[1], actual.shape[1]))\n",
    "            predicted_encodings = [np.where(r == np.max(r))[0][0] for r in predicted]\n",
    "            actual_encodings = [np.where(r == np.max(r))[0][0] for r in actual]\n",
    "            \n",
    "            for predicted_int, actual_int in zip(predicted_encodings, actual_encodings):\n",
    "                matrix[actual_int][predicted_int] += 1\n",
    "                \n",
    "            return matrix\n",
    "        \n",
    "        output = {}\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        \n",
    "        output[\"validation_eval\"] = self.classifier.evaluate(self.validation_in, self.validation_out, 512)\n",
    "        output[\"testing_eval\"] = self.classifier.evaluate(self.testing_in, self.testing_out, 512)\n",
    "        output[\"validation_confusion\"] = confusionMatrix(self.classifier.predict(self.validation_in, 512), self.validation_out)\n",
    "        output[\"testing_confusion\"] = confusionMatrix(self.classifier.predict(self.testing_in, 512), self.testing_out)\n",
    "        \n",
    "        sys.stdout = sys.__stdout__\n",
    "        \n",
    "        return output\n",
    "\n",
    "    \n",
    "    def steepen(self):\n",
    "        # Preserve old parameters\n",
    "        params = self.getParams()\n",
    "        \n",
    "        # Construct a new model\n",
    "        self.activation_param *= 2\n",
    "        self.classifier = self.makeClassifier()\n",
    "        \n",
    "        # Apply old parameters\n",
    "        self.setParams(params)\n",
    "    \n",
    "    \n",
    "    def configStr(self):\n",
    "        return \"Layers: {}; Output Categories: {}; Dropout: {}; Batch Size: {}\".format(\n",
    "            self.layer_sizes, self.output_categories, self.dropout, self.batch_size)\n",
    "    \n",
    "    \n",
    "    def getParams(self):\n",
    "        return [layer.get_weights() for layer in self.classifier.layers if isinstance(layer, tf.keras.layers.Dense)]\n",
    "    \n",
    "    \n",
    "    def setParams(self, params):\n",
    "        layers = [layer for layer in self.classifier.layers if isinstance(layer, tf.keras.layers.Dense)]\n",
    "        for layer, param in zip(layers, params):\n",
    "            layer.set_weights(param)\n",
    "    \n",
    "    \n",
    "    def makeSparse(self, p):\n",
    "        self.sparsity = [layer.makeSparse(p) for layer in self.sparse_layers]\n",
    "        return self.sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMETERS = {\n",
    "    \"df\": df_training.copy(),\n",
    "    \"df_validation\": df_valid.copy(),\n",
    "    \"df_testing\": df_test.copy(),\n",
    "    \"layer_sizes\": (70,),\n",
    "    \"output_categories\": \"rapid\",\n",
    "    \"dropout\": 0.1,\n",
    "    \"batch_size\": 64}\n",
    "\n",
    "def newNeuralNetwork():\n",
    "    return NeuralNetwork(**HYPERPARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseTraining:\n",
    "    \n",
    "    \n",
    "    ## Dummy class to make data more structured and break up logical flow of process\n",
    "    class Cycle:\n",
    "        \n",
    "        def __init__(self, nn):\n",
    "            \n",
    "            self.output = {}\n",
    "            \n",
    "            ## Train until the accuracy of the validation data decays\n",
    "            self.output[\"training_history\"] = nn.train(100).history\n",
    "            \n",
    "            ## Increase the sparsity (reduce number of weights by 20%)\n",
    "            self.output[\"final_sparsity\"] = nn.makeSparse(0.2)\n",
    "            \n",
    "            ## Store final weights and biases and sparsity matrix\n",
    "            self.output[\"final_params\"] = nn.getParams()\n",
    "            \n",
    "            ## Store final evaluation after increase of sparsity\n",
    "            self.output[\"final_eval\"] = nn.evaluate()\n",
    "            \n",
    "            \n",
    "        def steepen(self):\n",
    "            \n",
    "            ## Create a new neural network and initialize to old parameters\n",
    "            nn = newNeuralNetwork()\n",
    "            nn.setParams(self.output[\"final_params\"])\n",
    "            nn.sparsity = self.output[\"final_sparsity\"]\n",
    "            \n",
    "            self.output[\"steepening\"] = []\n",
    "            \n",
    "            ## Steepen the activation function and train\n",
    "            for i in range(9):\n",
    "                nn.steepen()\n",
    "                training_history = nn.train(100).history\n",
    "                self.output[\"steepening\"].append({\n",
    "                    \"training_history\": training_history,\n",
    "                    \"final_params\": nn.getParams(),\n",
    "                    \"final_eval\": nn.evaluate(),\n",
    "                    \"steepness\": nn.activation_param\n",
    "                })\n",
    "        \n",
    "        \n",
    "        def serialize(self):\n",
    "            return self.output\n",
    "        \n",
    "    \n",
    "    def __init__(self, nn):\n",
    "        \n",
    "        self.nn_config = nn.classifier.get_config()\n",
    "        \n",
    "        # Train 30 cycles until sparsity is approx. 99.9%\n",
    "        self.results = []\n",
    "        for i in range(30):\n",
    "            cycle = SparseTraining.Cycle(nn)\n",
    "            cycle.steepen()\n",
    "            self.results.append(cycle)\n",
    "            \n",
    "            with open(\"sparsity_pickles/sparsity-checkpoint-{}.pickle\".format(i), \"wb\") as output_file:\n",
    "                pickle.dump(cycle.serialize(), output_file)\n",
    "        \n",
    "        \n",
    "    def serialize(self):\n",
    "        \n",
    "        return {\n",
    "            \"results\": [cycle.serialize() for cycle in self.results],\n",
    "            \"hyperparameters\": {\n",
    "                \"layer_sizes\": HYPERPARAMETERS[\"layer_sizes\"],\n",
    "                \"output_categories\": HYPERPARAMETERS[\"layer_sizes\"],\n",
    "                \"dropout\": HYPERPARAMETERS[\"layer_sizes\"],\n",
    "                \"batch_size\": HYPERPARAMETERS[\"layer_sizes\"]},\n",
    "            \"nn_config\": self.nn_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"sparsity_pickles\"):\n",
    "    os.makedirs(\"sparsity_pickles\")\n",
    "else:\n",
    "    raise ValueError(\"The output directory has not been vacated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Sparsity = 0.0, Steepness = 1.0): loss = 0.677, accuracy = 0.574, auc = 0.603, val_loss = 0.677, val_accuracy = 0.592, val_auc = 0.612\n",
      "Epoch 2 (Sparsity = 0.0, Steepness = 1.0): loss = 0.664, accuracy = 0.594, auc = 0.633, val_loss = 0.702, val_accuracy = 0.560, val_auc = 0.562\n",
      "Epoch 3 (Sparsity = 0.0, Steepness = 1.0): loss = 0.661, accuracy = 0.599, auc = 0.640, val_loss = 0.641, val_accuracy = 0.658, val_auc = 0.714\n",
      "Epoch 4 (Sparsity = 0.0, Steepness = 1.0): loss = 0.660, accuracy = 0.602, auc = 0.643, val_loss = 0.659, val_accuracy = 0.624, val_auc = 0.670\n",
      "Epoch 5 (Sparsity = 0.0, Steepness = 1.0): loss = 0.660, accuracy = 0.602, auc = 0.643, val_loss = 0.694, val_accuracy = 0.563, val_auc = 0.588\n",
      "Epoch 6 (Sparsity = 0.0, Steepness = 1.0): loss = 0.659, accuracy = 0.602, auc = 0.645, val_loss = 0.681, val_accuracy = 0.583, val_auc = 0.620\n",
      "Epoch 7 (Sparsity = 0.0, Steepness = 1.0): loss = 0.658, accuracy = 0.604, auc = 0.647, val_loss = 0.655, val_accuracy = 0.617, val_auc = 0.673\n",
      "Epoch 8 (Sparsity = 0.0, Steepness = 1.0): loss = 0.658, accuracy = 0.605, auc = 0.648, val_loss = 0.671, val_accuracy = 0.586, val_auc = 0.632\n"
     ]
    }
   ],
   "source": [
    "nn = newNeuralNetwork()\n",
    "sparsity_trainer = SparseTraining(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"sparsity_pickles/sparsity.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(sparsity_trainer.serialize(), output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
